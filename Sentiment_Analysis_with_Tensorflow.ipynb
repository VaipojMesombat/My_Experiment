{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_with_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p> IDE: Colab </p>"
      ],
      "metadata": {
        "id": "CQH9LcjC0nQ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQiDXUx1lG09"
      },
      "outputs": [],
      "source": [
        "import io,sys\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_data ():\n",
        "\n",
        "  (train_data,test_data),info = tfds.load ('imdb_reviews/subwords8k',split=(tfds.Split.TRAIN,tfds.Split.TEST),with_info=True,as_supervised=True)\n",
        "  encoder = info.features['text'].encoder\n",
        "  padded_shapes = ([None],())\n",
        "  train_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\n",
        "  test_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\n",
        "\n",
        "  return train_batches,test_batches,encoder\n"
      ],
      "metadata": {
        "id": "S5UTNdzwlKlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model (encoder, embedding_dim = 16):\n",
        "  \n",
        "  model = keras.Sequential ([layers.Embedding(encoder.vocab_size,embedding_dim),\n",
        "                           layers.GlobalAveragePooling1D(),\n",
        "                           layers.Dense(1,activation = 'sigmoid') ])\n",
        "  model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  history = model.fit(train_batches,epochs=10, validation_data=test_batches,validation_steps=20)  \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "ynw_hchvJ2WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data (history) :\n",
        "  \n",
        "  history_dict = history.history\n",
        "  acc = history_dict['accuracy']\n",
        "  val_acc = history_dict ['accuracy']\n",
        "  epochs = range (1,len (acc) + 1)\n",
        "  plt.figure (figsize=(12,9))\n",
        "  plt.figure (figsize=(12,9))\n",
        "  plt.plot (epochs,acc,'bo',label='train acc')\n",
        "  plt.plot (epochs, val_acc,'b', label = 'Validation acc')\n",
        "  plt.title ('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel ('Accuracy')\n",
        "  plt.legend (loc='lower right')\n",
        "  plt.ylim ((0.5,1))\n",
        "  plt.show ()\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "2mXhSchIUGXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_embeddings (model,encoder):\n",
        "  out_vectors = io.open ('vecs.tsv','w',encoding = 'UTF-8')\n",
        "  out_metadata =  io.open ('meta.tsv','w',encoding = 'UTF-8')\n",
        "  weights = model.layers[0].get_weights()[0]\n",
        "\n",
        "  for num,word in enumerate (encoder.subwords):\n",
        "    vec = weights[num+1]\n",
        "    out_metadata.write(word +'\\n')\n",
        "    out_vectors.write ('\\t'.join([str(x) for x in vec ]) + '\\n')\n",
        "  out_metadata.close()\n",
        "  out_vectors.close()\n",
        "  \n",
        "  return\n",
        "  "
      ],
      "metadata": {
        "id": "GRzfmwpONIP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches, test_batches,encoder = get_batch_data()\n",
        "model = get_model (encoder)\n",
        "history = model.fit(train_batches,epochs=10, validation_data=test_batches,validation_steps=20)\n",
        "#plot_history (history)\n",
        "retrieve_embeddings (model,encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "ydhjkeQ9gagX",
        "outputId": "9f9ec0b5-9394-4e8d-d4dd-a9edad3bfbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.6334 - accuracy: 0.6958 - val_loss: 0.5248 - val_accuracy: 0.8050\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 15s 6ms/step - loss: 0.4617 - accuracy: 0.8414 - val_loss: 0.3819 - val_accuracy: 0.8950\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 15s 6ms/step - loss: 0.3623 - accuracy: 0.8802 - val_loss: 0.3701 - val_accuracy: 0.8800\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.3076 - accuracy: 0.8970 - val_loss: 0.3731 - val_accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 16s 7ms/step - loss: 0.2726 - accuracy: 0.9077 - val_loss: 0.4000 - val_accuracy: 0.8650\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2489 - accuracy: 0.9162 - val_loss: 0.3410 - val_accuracy: 0.8700\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2273 - accuracy: 0.9234 - val_loss: 0.2585 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2137 - accuracy: 0.9299 - val_loss: 0.3094 - val_accuracy: 0.8850\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 15s 6ms/step - loss: 0.1980 - accuracy: 0.9342 - val_loss: 0.3798 - val_accuracy: 0.8700\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 15s 6ms/step - loss: 0.1897 - accuracy: 0.9383 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1783 - accuracy: 0.9431 - val_loss: 0.2977 - val_accuracy: 0.9000\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1688 - accuracy: 0.9462 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1586 - accuracy: 0.9485 - val_loss: 0.4077 - val_accuracy: 0.8650\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1519 - accuracy: 0.9521 - val_loss: 0.4198 - val_accuracy: 0.8650\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1441 - accuracy: 0.9542 - val_loss: 0.5602 - val_accuracy: 0.8550\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1392 - accuracy: 0.9577 - val_loss: 0.3432 - val_accuracy: 0.8650\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1306 - accuracy: 0.9596 - val_loss: 0.4206 - val_accuracy: 0.8600\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 15s 6ms/step - loss: 0.1262 - accuracy: 0.9619 - val_loss: 0.3393 - val_accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1213 - accuracy: 0.9642 - val_loss: 0.4941 - val_accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.1166 - accuracy: 0.9651 - val_loss: 0.4337 - val_accuracy: 0.8750\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bad01db92496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_history\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mretrieve_embeddings\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieve_embeddings (model,encoder)"
      ],
      "metadata": {
        "id": "XTvDoVoiiLJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IhZ2Vkpfjyaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}